/home/tvg/miniconda3/envs/ml-graphs/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/home/tvg/miniconda3/envs/ml-graphs/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/home/tvg/miniconda3/envs/ml-graphs/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/home/tvg/miniconda3/envs/ml-graphs/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/home/tvg/miniconda3/envs/ml-graphs/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/home/tvg/miniconda3/envs/ml-graphs/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Seed set to 42
Loading cached data...
Done!
*** Training run 1 ***

Training with config: {'base_lr': 0.001, 'hidden_channels': 32, 'out_channels': 32, 'weight_decay': 0.0001, 'num_epochs': 100, 'log_every': 5, 'patience': 15}
Train edges: 28254
Val edges: 9076
Test edges: 9543
Nodes: 2070
Untrained Val AUC: 0.6227
Untrained Test AUC: 0.5424
Epoch 000 | Loss: 2.1329 | Val AUC: 0.6290 | LR: 0.001000
Epoch 005 | Loss: 1.1961 | Val AUC: 0.7939 | LR: 0.001000
Epoch 010 | Loss: 0.8257 | Val AUC: 0.7500 | LR: 0.001000
Epoch 015 | Loss: 0.6922 | Val AUC: 0.6878 | LR: 0.001000
Epoch 020 | Loss: 0.6185 | Val AUC: 0.5881 | LR: 0.001000
Epoch 025 | Loss: 0.5810 | Val AUC: 0.6265 | LR: 0.001000
Epoch 030 | Loss: 0.5459 | Val AUC: 0.8099 | LR: 0.001000
Epoch 035 | Loss: 0.5632 | Val AUC: 0.7928 | LR: 0.001000
Epoch 040 | Loss: 0.5313 | Val AUC: 0.7600 | LR: 0.001000
Epoch 045 | Loss: 0.5179 | Val AUC: 0.7399 | LR: 0.001000
Epoch 050 | Loss: 0.5220 | Val AUC: 0.7324 | LR: 0.001000
Epoch 055 | Loss: 0.4974 | Val AUC: 0.7252 | LR: 0.001000
Epoch 060 | Loss: 0.4908 | Val AUC: 0.7177 | LR: 0.001000
Epoch 065 | Loss: 0.5532 | Val AUC: 0.7150 | LR: 0.001000
Epoch 070 | Loss: 0.4832 | Val AUC: 0.7148 | LR: 0.001000
Epoch 075 | Loss: 0.5444 | Val AUC: 0.7137 | LR: 0.001000
Epoch 080 | Loss: 0.4928 | Val AUC: 0.7152 | LR: 0.001000
Epoch 085 | Loss: 0.4751 | Val AUC: 0.7165 | LR: 0.001000
Epoch 090 | Loss: 0.4850 | Val AUC: 0.7166 | LR: 0.000500
Epoch 095 | Loss: 0.4803 | Val AUC: 0.7158 | LR: 0.000500
Testing...
Test AUC: 0.6431
*** Training run 2 ***

Training with config: {'base_lr': 0.001, 'hidden_channels': 32, 'out_channels': 32, 'weight_decay': 0.0001, 'num_epochs': 100, 'log_every': 5, 'patience': 15}
Train edges: 28254
Val edges: 9076
Test edges: 9543
Nodes: 2070
Untrained Val AUC: 0.7935
Untrained Test AUC: 0.8160
Epoch 000 | Loss: 2.1400 | Val AUC: 0.7320 | LR: 0.001000
Epoch 005 | Loss: 1.0182 | Val AUC: 0.5915 | LR: 0.001000
Epoch 010 | Loss: 0.8086 | Val AUC: 0.6606 | LR: 0.001000
Epoch 015 | Loss: 0.6683 | Val AUC: 0.6672 | LR: 0.001000
Epoch 020 | Loss: 0.5830 | Val AUC: 0.8766 | LR: 0.001000
Epoch 025 | Loss: 0.5364 | Val AUC: 0.8780 | LR: 0.001000
Epoch 030 | Loss: 0.5986 | Val AUC: 0.8437 | LR: 0.001000
Epoch 035 | Loss: 0.5471 | Val AUC: 0.8281 | LR: 0.001000
Epoch 040 | Loss: 0.5248 | Val AUC: 0.8323 | LR: 0.001000
Epoch 045 | Loss: 0.5239 | Val AUC: 0.8247 | LR: 0.001000
Epoch 050 | Loss: 0.4949 | Val AUC: 0.8571 | LR: 0.001000
Epoch 055 | Loss: 0.5162 | Val AUC: 0.8498 | LR: 0.001000
Epoch 060 | Loss: 0.5138 | Val AUC: 0.8302 | LR: 0.001000
Epoch 065 | Loss: 0.5013 | Val AUC: 0.6927 | LR: 0.001000
Epoch 070 | Loss: 0.4735 | Val AUC: 0.6924 | LR: 0.001000
Epoch 075 | Loss: 0.4766 | Val AUC: 0.6925 | LR: 0.001000
Epoch 080 | Loss: 0.4927 | Val AUC: 0.6926 | LR: 0.001000
Epoch 085 | Loss: 0.4623 | Val AUC: 0.6933 | LR: 0.000500
Epoch 090 | Loss: 0.4588 | Val AUC: 0.6935 | LR: 0.000500
Epoch 095 | Loss: 0.4847 | Val AUC: 0.6933 | LR: 0.000500
Testing...
Test AUC: 0.6399
*** Training run 3 ***

Training with config: {'base_lr': 0.001, 'hidden_channels': 32, 'out_channels': 32, 'weight_decay': 0.0001, 'num_epochs': 100, 'log_every': 5, 'patience': 15}
Train edges: 28254
Val edges: 9076
Test edges: 9543
Nodes: 2070
Untrained Val AUC: 0.6707
Untrained Test AUC: 0.6022
Epoch 000 | Loss: 2.1228 | Val AUC: 0.4894 | LR: 0.001000
Epoch 005 | Loss: 1.1771 | Val AUC: 0.5376 | LR: 0.001000
Epoch 010 | Loss: 0.8317 | Val AUC: 0.6069 | LR: 0.001000
Epoch 015 | Loss: 0.7040 | Val AUC: 0.6354 | LR: 0.001000
Epoch 020 | Loss: 0.5837 | Val AUC: 0.6422 | LR: 0.001000
Epoch 025 | Loss: 0.5897 | Val AUC: 0.6475 | LR: 0.001000
Epoch 030 | Loss: 0.5354 | Val AUC: 0.8552 | LR: 0.001000
Epoch 035 | Loss: 0.5440 | Val AUC: 0.9074 | LR: 0.001000
Epoch 040 | Loss: 0.5265 | Val AUC: 0.9050 | LR: 0.001000
Epoch 045 | Loss: 0.5370 | Val AUC: 0.9073 | LR: 0.001000
Epoch 050 | Loss: 0.5042 | Val AUC: 0.8707 | LR: 0.001000
Epoch 055 | Loss: 0.4894 | Val AUC: 0.8695 | LR: 0.001000
Epoch 060 | Loss: 0.4893 | Val AUC: 0.8875 | LR: 0.001000
Epoch 065 | Loss: 0.5032 | Val AUC: 0.8726 | LR: 0.001000
Epoch 070 | Loss: 0.4984 | Val AUC: 0.8476 | LR: 0.001000
Epoch 075 | Loss: 0.4649 | Val AUC: 0.8277 | LR: 0.001000
Epoch 080 | Loss: 0.4571 | Val AUC: 0.7784 | LR: 0.001000
Epoch 085 | Loss: 0.4801 | Val AUC: 0.7852 | LR: 0.001000
Epoch 090 | Loss: 0.4538 | Val AUC: 0.8155 | LR: 0.001000
Epoch 095 | Loss: 0.4797 | Val AUC: 0.8092 | LR: 0.000500
Testing...
Test AUC: 0.7057
*** Training run 4 ***

Training with config: {'base_lr': 0.001, 'hidden_channels': 32, 'out_channels': 32, 'weight_decay': 0.0001, 'num_epochs': 100, 'log_every': 5, 'patience': 15}
Train edges: 28254
Val edges: 9076
Test edges: 9543
Nodes: 2070
Untrained Val AUC: 0.6875
Untrained Test AUC: 0.5862
Epoch 000 | Loss: 2.1810 | Val AUC: 0.6864 | LR: 0.001000
Epoch 005 | Loss: 1.0838 | Val AUC: 0.8258 | LR: 0.001000
Epoch 010 | Loss: 0.7768 | Val AUC: 0.6638 | LR: 0.001000
Epoch 015 | Loss: 0.6348 | Val AUC: 0.6645 | LR: 0.001000
Epoch 020 | Loss: 0.5563 | Val AUC: 0.6407 | LR: 0.001000
Epoch 025 | Loss: 0.5467 | Val AUC: 0.6021 | LR: 0.001000
Epoch 030 | Loss: 0.5451 | Val AUC: 0.5891 | LR: 0.001000
Epoch 035 | Loss: 0.5351 | Val AUC: 0.7751 | LR: 0.001000
Epoch 040 | Loss: 0.5184 | Val AUC: 0.7670 | LR: 0.001000
Epoch 045 | Loss: 0.5282 | Val AUC: 0.7559 | LR: 0.001000
Epoch 050 | Loss: 0.5053 | Val AUC: 0.7423 | LR: 0.001000
Epoch 055 | Loss: 0.4728 | Val AUC: 0.7330 | LR: 0.001000
Epoch 060 | Loss: 0.4815 | Val AUC: 0.7314 | LR: 0.001000
Epoch 065 | Loss: 0.5002 | Val AUC: 0.7316 | LR: 0.000500
Epoch 070 | Loss: 0.4823 | Val AUC: 0.7225 | LR: 0.000500
Epoch 075 | Loss: 0.4789 | Val AUC: 0.7200 | LR: 0.000500
Epoch 080 | Loss: 0.4993 | Val AUC: 0.7200 | LR: 0.000500
Early stopping at epoch 80
Testing...
Test AUC: 0.6532
*** Training run 5 ***

Training with config: {'base_lr': 0.001, 'hidden_channels': 32, 'out_channels': 32, 'weight_decay': 0.0001, 'num_epochs': 100, 'log_every': 5, 'patience': 15}
Train edges: 28254
Val edges: 9076
Test edges: 9543
Nodes: 2070
Untrained Val AUC: 0.5863
Untrained Test AUC: 0.6472
Epoch 000 | Loss: 2.1688 | Val AUC: 0.5223 | LR: 0.001000
Epoch 005 | Loss: 1.1718 | Val AUC: 0.5663 | LR: 0.001000
Epoch 010 | Loss: 0.8140 | Val AUC: 0.6705 | LR: 0.001000
Epoch 015 | Loss: 0.6803 | Val AUC: 0.6775 | LR: 0.001000
Epoch 020 | Loss: 0.5771 | Val AUC: 0.6801 | LR: 0.001000
Epoch 025 | Loss: 0.5358 | Val AUC: 0.8844 | LR: 0.001000
Epoch 030 | Loss: 0.5781 | Val AUC: 0.8643 | LR: 0.001000
Epoch 035 | Loss: 0.5107 | Val AUC: 0.6587 | LR: 0.001000
Epoch 040 | Loss: 0.5144 | Val AUC: 0.8416 | LR: 0.001000
Epoch 045 | Loss: 0.4866 | Val AUC: 0.8221 | LR: 0.001000
Epoch 050 | Loss: 0.4773 | Val AUC: 0.8229 | LR: 0.001000
Epoch 055 | Loss: 0.4869 | Val AUC: 0.8175 | LR: 0.001000
Epoch 060 | Loss: 0.4762 | Val AUC: 0.8035 | LR: 0.001000
Epoch 065 | Loss: 0.4774 | Val AUC: 0.7998 | LR: 0.001000
Epoch 070 | Loss: 0.4646 | Val AUC: 0.8037 | LR: 0.001000
Epoch 075 | Loss: 0.4924 | Val AUC: 0.7952 | LR: 0.001000
Epoch 080 | Loss: 0.4562 | Val AUC: 0.7929 | LR: 0.001000
Epoch 085 | Loss: 0.4616 | Val AUC: 0.7924 | LR: 0.000500
Epoch 090 | Loss: 0.4692 | Val AUC: 0.7912 | LR: 0.000500
Epoch 095 | Loss: 0.4621 | Val AUC: 0.7785 | LR: 0.000500
Testing...
Test AUC: 0.6662
*** Training run 6 ***

Training with config: {'base_lr': 0.001, 'hidden_channels': 32, 'out_channels': 32, 'weight_decay': 0.0001, 'num_epochs': 100, 'log_every': 5, 'patience': 15}
Train edges: 28254
Val edges: 9076
Test edges: 9543
Nodes: 2070
Untrained Val AUC: 0.7708
Untrained Test AUC: 0.3806
Epoch 000 | Loss: 2.1337 | Val AUC: 0.7952 | LR: 0.001000
Epoch 005 | Loss: 1.1420 | Val AUC: 0.6301 | LR: 0.001000
Epoch 010 | Loss: 0.8242 | Val AUC: 0.6008 | LR: 0.001000
Epoch 015 | Loss: 0.7260 | Val AUC: 0.5555 | LR: 0.001000
Epoch 020 | Loss: 0.6299 | Val AUC: 0.5821 | LR: 0.001000
Epoch 025 | Loss: 0.5442 | Val AUC: 0.7550 | LR: 0.001000
Epoch 030 | Loss: 0.5604 | Val AUC: 0.8347 | LR: 0.001000
Epoch 035 | Loss: 0.5044 | Val AUC: 0.8529 | LR: 0.001000
Epoch 040 | Loss: 0.5450 | Val AUC: 0.8275 | LR: 0.001000
Epoch 045 | Loss: 0.5351 | Val AUC: 0.7915 | LR: 0.001000/home/tvg/miniconda3/envs/ml-graphs/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/home/tvg/miniconda3/envs/ml-graphs/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/home/tvg/miniconda3/envs/ml-graphs/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/home/tvg/miniconda3/envs/ml-graphs/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(

Epoch 050 | Loss: 0.4809 | Val AUC: 0.7879 | LR: 0.001000
Epoch 055 | Loss: 0.5207 | Val AUC: 0.7795 | LR: 0.001000
Epoch 060 | Loss: 0.4889 | Val AUC: 0.7758 | LR: 0.001000
Epoch 065 | Loss: 0.4826 | Val AUC: 0.7893 | LR: 0.001000
Epoch 070 | Loss: 0.5281 | Val AUC: 0.7506 | LR: 0.001000
Epoch 075 | Loss: 0.5015 | Val AUC: 0.7356 | LR: 0.001000
Epoch 080 | Loss: 0.4805 | Val AUC: 0.7316 | LR: 0.001000
Epoch 085 | Loss: 0.4868 | Val AUC: 0.7319 | LR: 0.001000
Epoch 090 | Loss: 0.5121 | Val AUC: 0.7194 | LR: 0.001000
Epoch 095 | Loss: 0.5213 | Val AUC: 0.7270 | LR: 0.000500
Testing...
Test AUC: 0.6506
*** Training run 7 ***

Training with config: {'base_lr': 0.001, 'hidden_channels': 32, 'out_channels': 32, 'weight_decay': 0.0001, 'num_epochs': 100, 'log_every': 5, 'patience': 15}
Train edges: 28254
Val edges: 9076
Test edges: 9543
Nodes: 2070
Untrained Val AUC: 0.2881
Untrained Test AUC: 0.3305
Epoch 000 | Loss: 2.1787 | Val AUC: 0.4151 | LR: 0.001000
Epoch 005 | Loss: 1.2070 | Val AUC: 0.7210 | LR: 0.001000
Epoch 010 | Loss: 0.8642 | Val AUC: 0.6984 | LR: 0.001000
Epoch 015 | Loss: 0.6794 | Val AUC: 0.6936 | LR: 0.001000
Epoch 020 | Loss: 0.6537 | Val AUC: 0.6883 | LR: 0.001000
Epoch 025 | Loss: 0.5657 | Val AUC: 0.9084 | LR: 0.001000
Epoch 030 | Loss: 0.6082 | Val AUC: 0.9167 | LR: 0.001000
Epoch 035 | Loss: 0.5494 | Val AUC: 0.9141 | LR: 0.001000
Epoch 040 | Loss: 0.5941 | Val AUC: 0.9015 | LR: 0.001000
Epoch 045 | Loss: 0.5280 | Val AUC: 0.8773 | LR: 0.001000
Epoch 050 | Loss: 0.5404 | Val AUC: 0.8756 | LR: 0.001000
Epoch 055 | Loss: 0.5285 | Val AUC: 0.8870 | LR: 0.001000
Epoch 060 | Loss: 0.5089 | Val AUC: 0.8700 | LR: 0.001000
Epoch 065 | Loss: 0.4932 | Val AUC: 0.8023 | LR: 0.001000
Epoch 070 | Loss: 0.4737 | Val AUC: 0.7928 | LR: 0.001000
Epoch 075 | Loss: 0.4941 | Val AUC: 0.8103 | LR: 0.001000
Epoch 080 | Loss: 0.4697 | Val AUC: 0.8037 | LR: 0.001000
Epoch 085 | Loss: 0.4748 | Val AUC: 0.8043 | LR: 0.001000
Epoch 090 | Loss: 0.4620 | Val AUC: 0.8062 | LR: 0.000500
Epoch 095 | Loss: 0.4622 | Val AUC: 0.8103 | LR: 0.000500
Testing...
Test AUC: 0.6449
*** Training run 8 ***

Training with config: {'base_lr': 0.001, 'hidden_channels': 32, 'out_channels': 32, 'weight_decay': 0.0001, 'num_epochs': 100, 'log_every': 5, 'patience': 15}
Train edges: 28254
Val edges: 9076
Test edges: 9543
Nodes: 2070
Untrained Val AUC: 0.7319
Untrained Test AUC: 0.7468
Epoch 000 | Loss: 2.1601 | Val AUC: 0.8401 | LR: 0.001000
Epoch 005 | Loss: 1.0814 | Val AUC: 0.7853 | LR: 0.001000
Epoch 010 | Loss: 0.8102 | Val AUC: 0.8265 | LR: 0.001000
Epoch 015 | Loss: 0.6846 | Val AUC: 0.8166 | LR: 0.001000
Epoch 020 | Loss: 0.6073 | Val AUC: 0.8093 | LR: 0.001000
Epoch 025 | Loss: 0.5852 | Val AUC: 0.8202 | LR: 0.001000
Epoch 030 | Loss: 0.5425 | Val AUC: 0.8443 | LR: 0.001000
Epoch 035 | Loss: 0.5218 | Val AUC: 0.8784 | LR: 0.001000
Epoch 040 | Loss: 0.5409 | Val AUC: 0.8548 | LR: 0.001000
Epoch 045 | Loss: 0.5254 | Val AUC: 0.7726 | LR: 0.001000
Epoch 050 | Loss: 0.5356 | Val AUC: 0.7426 | LR: 0.001000
Epoch 055 | Loss: 0.5383 | Val AUC: 0.7331 | LR: 0.001000
Epoch 060 | Loss: 0.4974 | Val AUC: 0.7297 | LR: 0.001000
Epoch 065 | Loss: 0.5163 | Val AUC: 0.7246 | LR: 0.001000
Epoch 070 | Loss: 0.5485 | Val AUC: 0.7063 | LR: 0.001000
Epoch 075 | Loss: 0.5072 | Val AUC: 0.7039 | LR: 0.001000
Epoch 080 | Loss: 0.4909 | Val AUC: 0.7050 | LR: 0.001000
Epoch 085 | Loss: 0.4844 | Val AUC: 0.7060 | LR: 0.001000
Epoch 090 | Loss: 0.5031 | Val AUC: 0.6959 | LR: 0.001000
Epoch 095 | Loss: 0.4889 | Val AUC: 0.6962 | LR: 0.000500
Testing...
Test AUC: 0.6618
*** Training run 9 ***

Training with config: {'base_lr': 0.001, 'hidden_channels': 32, 'out_channels': 32, 'weight_decay': 0.0001, 'num_epochs': 100, 'log_every': 5, 'patience': 15}
Train edges: 28254
Val edges: 9076
Test edges: 9543
Nodes: 2070
Untrained Val AUC: 0.6575
Untrained Test AUC: 0.7859
Epoch 000 | Loss: 2.1299 | Val AUC: 0.7299 | LR: 0.001000
Epoch 005 | Loss: 1.1653 | Val AUC: 0.7443 | LR: 0.001000
Epoch 010 | Loss: 0.7876 | Val AUC: 0.7683 | LR: 0.001000
Epoch 015 | Loss: 0.6656 | Val AUC: 0.7890 | LR: 0.001000
Epoch 020 | Loss: 0.6134 | Val AUC: 0.8244 | LR: 0.001000
Epoch 025 | Loss: 0.5692 | Val AUC: 0.8605 | LR: 0.001000
Epoch 030 | Loss: 0.5625 | Val AUC: 0.8969 | LR: 0.001000
Epoch 035 | Loss: 0.5524 | Val AUC: 0.8963 | LR: 0.001000
Epoch 040 | Loss: 0.5510 | Val AUC: 0.8743 | LR: 0.001000
Epoch 045 | Loss: 0.5190 | Val AUC: 0.8501 | LR: 0.001000
Epoch 050 | Loss: 0.5531 | Val AUC: 0.8483 | LR: 0.001000
Epoch 055 | Loss: 0.5126 | Val AUC: 0.8134 | LR: 0.001000
Epoch 060 | Loss: 0.5199 | Val AUC: 0.6926 | LR: 0.001000
Epoch 065 | Loss: 0.4869 | Val AUC: 0.6962 | LR: 0.001000
Epoch 070 | Loss: 0.5052 | Val AUC: 0.7045 | LR: 0.001000
Epoch 075 | Loss: 0.5266 | Val AUC: 0.7084 | LR: 0.001000
Epoch 080 | Loss: 0.4681 | Val AUC: 0.7088 | LR: 0.001000
Epoch 085 | Loss: 0.4655 | Val AUC: 0.7093 | LR: 0.001000
Epoch 090 | Loss: 0.4875 | Val AUC: 0.7095 | LR: 0.000500
Epoch 095 | Loss: 0.4865 | Val AUC: 0.7109 | LR: 0.000500
Testing...
Test AUC: 0.6422
*** Training run 10 ***

Training with config: {'base_lr': 0.001, 'hidden_channels': 32, 'out_channels': 32, 'weight_decay': 0.0001, 'num_epochs': 100, 'log_every': 5, 'patience': 15}
Train edges: 28254
Val edges: 9076
Test edges: 9543
Nodes: 2070
Untrained Val AUC: 0.5838
Untrained Test AUC: 0.4793
Epoch 000 | Loss: 2.2332 | Val AUC: 0.5921 | LR: 0.001000
Epoch 005 | Loss: 1.1372 | Val AUC: 0.6483 | LR: 0.001000
Epoch 010 | Loss: 0.8157 | Val AUC: 0.6458 | LR: 0.001000
Epoch 015 | Loss: 0.6629 | Val AUC: 0.6632 | LR: 0.001000
Epoch 020 | Loss: 0.6244 | Val AUC: 0.8446 | LR: 0.001000
Epoch 025 | Loss: 0.5783 | Val AUC: 0.9024 | LR: 0.001000
Epoch 030 | Loss: 0.5737 | Val AUC: 0.9049 | LR: 0.001000
Epoch 035 | Loss: 0.5474 | Val AUC: 0.8991 | LR: 0.001000
Epoch 040 | Loss: 0.5077 | Val AUC: 0.9050 | LR: 0.001000
Epoch 045 | Loss: 0.5135 | Val AUC: 0.8823 | LR: 0.001000
Epoch 050 | Loss: 0.5190 | Val AUC: 0.8542 | LR: 0.001000
Epoch 055 | Loss: 0.5102 | Val AUC: 0.8501 | LR: 0.001000
Epoch 060 | Loss: 0.4857 | Val AUC: 0.8801 | LR: 0.001000
Epoch 065 | Loss: 0.4882 | Val AUC: 0.8701 | LR: 0.001000
Epoch 070 | Loss: 0.4824 | Val AUC: 0.7287 | LR: 0.001000
Epoch 075 | Loss: 0.4759 | Val AUC: 0.7269 | LR: 0.001000
Epoch 080 | Loss: 0.4736 | Val AUC: 0.7269 | LR: 0.001000
Epoch 085 | Loss: 0.4664 | Val AUC: 0.7137 | LR: 0.001000
Epoch 090 | Loss: 0.5100 | Val AUC: 0.7139 | LR: 0.001000
Epoch 095 | Loss: 0.4853 | Val AUC: 0.7137 | LR: 0.001000
Testing...
Test AUC: 0.6451
*** Val AUC: 0.8755 ± 0.0338 ***

Grid Search Results:
Best validation AUC: 0.8755
Best configuration:
base_lr: 0.001
hidden_channels: 32
out_channels: 32
weight_decay: 0.0001
num_epochs: 100
log_every: 5
patience: 15
