{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004fc544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 1712.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "max_citations = -1\n",
    "\n",
    "# This json file has all the filtered data provided by OpenAlex API\n",
    "with open(\"../data/openalex_cs_papers.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Collecting author and co-authorship features\n",
    "for work in tqdm(data[\"results\"]):\n",
    "    authors = []\n",
    "    cited_by = work.get(\"cited_by_count\", 0)  \n",
    "\n",
    "    # Adding/updating attributes for each author\n",
    "    for author_data in work[\"authorships\"]:\n",
    "        author_id = author_data[\"author\"][\"id\"]\n",
    "        affiliation = (\n",
    "            author_data[\"institutions\"][0][\"display_name\"]\n",
    "            if author_data.get(\"institutions\")\n",
    "            else \"Unknown\"\n",
    "        )\n",
    "        \n",
    "        authors.append({\"id\": author_id, \"title\": work['title']})\n",
    "\n",
    "        # Custom attributes for author nodes\n",
    "        if author_id not in G:\n",
    "            G.add_node(\n",
    "                author_id,\n",
    "                affiliated_institution=affiliation,\n",
    "                citation_count=cited_by\n",
    "            )\n",
    "        else:\n",
    "            G.nodes[author_id][\"citation_count\"] += cited_by\n",
    "\n",
    "        max_citations = max(max_citations, G.nodes[author_id][\"citation_count\"])\n",
    "\n",
    "    # Adding co-authorship edges\n",
    "    for i in range(len(authors)):\n",
    "        for j in range(i + 1, len(authors)):\n",
    "            id_1, id_2 = authors[i][\"id\"], authors[j][\"id\"]\n",
    "            if G.has_edge(id_1, id_2):\n",
    "                G[id_1][id_2][\"title\"].append(authors[i][\"title\"])\n",
    "            else:\n",
    "                G.add_edge(id_1, id_2)\n",
    "                G[id_1][id_2][\"title\"] = [\n",
    "                    authors[i][\"title\"]\n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf50276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tvg/miniconda3/envs/ml-graphs/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0ae7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2070/2070 [00:06<00:00, 302.70it/s]\n"
     ]
    }
   ],
   "source": [
    "node_features_list = []\n",
    "\n",
    "for node_id in tqdm(G.nodes()):\n",
    "    node = G.nodes[node_id]\n",
    "    scaled_citation_count = node[\"citation_count\"] / max_citations\n",
    "    feat = [scaled_citation_count]\n",
    "    feat.extend(sentence_model.encode(node['affiliated_institution']).tolist())\n",
    "    node_features_list.append(torch.tensor(feat, dtype=torch.float))\n",
    "\n",
    "node_features = torch.stack(node_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08f1a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "institution_names = [G.nodes[node_id]['affiliated_institution'] for node_id in G.nodes()]\n",
    "institution_embeddings = sentence_model.encode(institution_names, convert_to_tensor=True).to('cuda')\n",
    "\n",
    "node_features_list = []\n",
    "for i, node_id in enumerate(G.nodes()):\n",
    "    node = G.nodes[node_id]\n",
    "    scaled_citation_count = torch.tensor([node[\"citation_count\"] / max_citations], dtype=torch.float).to('cuda')\n",
    "    feat = torch.cat((scaled_citation_count, institution_embeddings[i]))\n",
    "    node_features_list.append(feat)\n",
    "\n",
    "node_features = torch.stack(node_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0a0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43246 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m title_embeddings = []\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m title \u001b[38;5;129;01min\u001b[39;00m titles:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     title_embeddings.append(torch.tensor(\u001b[43msentence_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m(), dtype=torch.float))\n\u001b[32m     19\u001b[39m averaged_embedding = torch.stack(title_embeddings).mean(dim=\u001b[32m0\u001b[39m)\n\u001b[32m     20\u001b[39m edge_features_list.append(averaged_embedding)\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "edge_list = list(G.edges())\n",
    "edge_indices = torch.empty((2, 0), dtype=torch.long)\n",
    "edge_features = torch.empty((0, sentence_model.get_sentence_embedding_dimension()), dtype=torch.float)\n",
    "\n",
    "assert edge_list is not None\n",
    "\n",
    "node_to_idx = {node: i for i, node in enumerate(G.nodes())}\n",
    "mapped_edges = [[node_to_idx[u], node_to_idx[v]] for u, v in edge_list]\n",
    "edge_indices = torch.tensor(mapped_edges, dtype=torch.long).t().contiguous()\n",
    "edge_features_list = []\n",
    "\n",
    "for u, v in tqdm(edge_list):\n",
    "    titles = G[u][v].get('title', [])\n",
    "\n",
    "    title_embeddings = []\n",
    "    for title in titles:\n",
    "        title_embeddings.append(torch.tensor(sentence_model.encode(title), dtype=torch.float))\n",
    "    \n",
    "    averaged_embedding = torch.stack(title_embeddings).mean(dim=0)\n",
    "    edge_features_list.append(averaged_embedding)\n",
    "        \n",
    "edge_features = torch.stack(edge_features_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16d95804",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = list(G.edges())\n",
    "edge_indices = torch.empty((2, 0), dtype=torch.long)\n",
    "edge_features = torch.empty((0, sentence_model.get_sentence_embedding_dimension()), dtype=torch.float).to('cuda')\n",
    "\n",
    "assert edge_list is not None\n",
    "\n",
    "node_to_idx = {node: i for i, node in enumerate(G.nodes())}\n",
    "mapped_edges = [[node_to_idx[u], node_to_idx[v]] for u, v in edge_list]\n",
    "edge_indices = torch.tensor(mapped_edges, dtype=torch.long).t().contiguous().to('cuda')\n",
    "\n",
    "all_individual_titles = []\n",
    "title_slices = []\n",
    "current_idx = 0\n",
    "for u, v in edge_list:\n",
    "    titles = G[u][v]['title']\n",
    "    all_individual_titles.extend(titles)\n",
    "    title_slices.append((current_idx, current_idx + len(titles)))\n",
    "    current_idx += len(titles)\n",
    "\n",
    "batched_title_embeddings = sentence_model.encode(all_individual_titles, convert_to_tensor=True).to('cuda')\n",
    "\n",
    "edge_features_list = []\n",
    "for i, (u, v) in enumerate(edge_list):\n",
    "    start_idx, end_idx = title_slices[i]\n",
    "    individual_embeddings_for_edge = batched_title_embeddings[start_idx:end_idx]\n",
    "    averaged_embedding = individual_embeddings_for_edge.mean(dim=0)\n",
    "    edge_features_list.append(averaged_embedding)\n",
    "\n",
    "edge_features = torch.stack(edge_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5509498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = Data(\n",
    "    x=node_features,\n",
    "    edge_index=edge_indices,\n",
    "    edge_attr=edge_features\n",
    ")\n",
    "\n",
    "dataset = [graph_data]\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c03bc6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of batch object: <class 'abc.DataBatch'>\n",
      "Batch content: DataBatch(x=[2070, 385], edge_index=[2, 43246], edge_attr=[43246, 384], batch=[2070], ptr=[2])\n",
      "\n",
      "Node features (x):\n",
      "  Shape: torch.Size([2070, 385])\n",
      "  Device: cuda:0\n",
      "\n",
      "Edge indices (edge_index):\n",
      "  Shape: torch.Size([2, 43246])\n",
      "  Device: cuda:0\n",
      "\n",
      "Edge features (edge_attr):\n",
      "  Shape: torch.Size([43246, 384])\n",
      "  Device: cuda:0\n",
      "\n",
      "Number of nodes: 2070\n",
      "Number of edges: 43246\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'single_batch_dataloader' is the DataLoader object you created\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(f\"Type of batch object: {type(batch)}\")\n",
    "    print(f\"Batch content: {batch}\")\n",
    "    \n",
    "    print(f\"\\nNode features (x):\")\n",
    "    print(f\"  Shape: {batch.x.shape}\")\n",
    "    print(f\"  Device: {batch.x.device}\")\n",
    "    \n",
    "    print(f\"\\nEdge indices (edge_index):\")\n",
    "    print(f\"  Shape: {batch.edge_index.shape}\")\n",
    "    print(f\"  Device: {batch.edge_index.device}\")\n",
    "    \n",
    "    print(f\"\\nEdge features (edge_attr):\")\n",
    "    print(f\"  Shape: {batch.edge_attr.shape}\")\n",
    "    print(f\"  Device: {batch.edge_attr.device}\")\n",
    "\n",
    "    # You can also check other attributes of the Data object\n",
    "    print(f\"\\nNumber of nodes: {batch.num_nodes}\")\n",
    "    print(f\"Number of edges: {batch.num_edges}\")\n",
    "\n",
    "    # Break after the first (and only) batch if you only want to inspect it\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e2d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
